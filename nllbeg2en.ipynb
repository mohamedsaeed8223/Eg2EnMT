{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T16:44:49.485386Z","iopub.status.busy":"2024-05-26T16:44:49.485072Z","iopub.status.idle":"2024-05-26T16:45:03.253294Z","shell.execute_reply":"2024-05-26T16:45:03.252351Z","shell.execute_reply.started":"2024-05-26T16:44:49.485361Z"},"id":"kCSWtpkxTxjp","scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\n","Collecting evaluate\n","  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.22.2)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n","Collecting portalocker (from sacrebleu)\n","  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2023.12.25)\n","Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n","Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n","Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.2.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Installing collected packages: portalocker, sacrebleu, evaluate\n","Successfully installed evaluate-0.4.2 portalocker-2.8.2 sacrebleu-2.4.2\n"]}],"source":["# Transformers installation\n","! pip install datasets evaluate sacrebleu\n","# To install from source instead of the last release, comment the command above and uncomment the following one.\n","# ! pip install git+https://github.com/huggingface/transformers.git"]},{"cell_type":"markdown","metadata":{"id":"70Jg9zN-Txjs"},"source":["# Translation"]},{"cell_type":"markdown","metadata":{"id":"KpMQU4D7Txju"},"source":["Translation converts a sequence of text from one language to another. It is one of several tasks you can formulate as a sequence-to-sequence problem, a powerful framework for returning some output from an input, like translation or summarization. Translation systems are commonly used for translation between different language texts, but it can also be used for speech or some combination in between like text-to-speech or speech-to-text.\n","\n","This guide will show you how to:\n","\n","1. Finetune facebook's [NLLB](https://huggingface.co/facebook/nllb-200-distilled-600M) on the custom Egyptian to English Dataset.\n","2. Use your finetuned model for inference.\n","\n","<Tip>\n","The task illustrated in this tutorial is supported by the following model architectures:\n","\n","<!--This tip is automatically generated by `make fix-copies`, do not fill manually!-->\n","\n","[BART](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/bart), [BigBird-Pegasus](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/bigbird_pegasus), [Blenderbot](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/blenderbot), [BlenderbotSmall](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/blenderbot-small), [Encoder decoder](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/encoder-decoder), [FairSeq Machine-Translation](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/fsmt), [GPTSAN-japanese](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gptsan-japanese), [LED](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/led), [LongT5](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/longt5), [M2M100](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/m2m_100), [Marian](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/marian), [mBART](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mbart), [MT5](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mt5), [MVP](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mvp), [NLLB](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/nllb), [NLLB-MOE](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/nllb-moe), [Pegasus](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/pegasus), [PEGASUS-X](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/pegasus_x), [PLBart](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/plbart), [ProphetNet](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/prophetnet), [SwitchTransformers](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/switch_transformers), [T5](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/t5), [XLM-ProphetNet](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xlm-prophetnet)\n","\n","<!--End of the generated tip-->\n","\n","</Tip>\n","\n","Before you begin, make sure you have all the necessary libraries installed:\n","\n","```bash\n","pip install transformers datasets evaluate sacrebleu\n","```\n","\n","We encourage you to login to your Hugging Face account so you can upload and share your model with the community. When prompted, enter your token to login:"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T16:45:14.573057Z","iopub.status.busy":"2024-05-26T16:45:14.572134Z","iopub.status.idle":"2024-05-26T16:45:14.592700Z","shell.execute_reply":"2024-05-26T16:45:14.592082Z","shell.execute_reply.started":"2024-05-26T16:45:14.573025Z"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715107856364,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"1btijRA7Txju","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ba967311b1d440f59e3429a06fffcc6d","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"]},{"cell_type":"markdown","metadata":{"id":"UrVJWM41Txju"},"source":["## Load Our Custom dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T16:45:23.981991Z","iopub.status.busy":"2024-05-26T16:45:23.981664Z","iopub.status.idle":"2024-05-26T16:45:30.140486Z","shell.execute_reply":"2024-05-26T16:45:30.139911Z","shell.execute_reply.started":"2024-05-26T16:45:23.981967Z"},"executionInfo":{"elapsed":14428,"status":"ok","timestamp":1715107883672,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"hW7k3OUFTxjv","outputId":"c9615268-e158-4ab5-d342-22abd87be0e4","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"34c91329b18f481e8a254d1506df4aee","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/333 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Downloading data: 100%|██████████| 2.61M/2.61M [00:00<00:00, 4.20MB/s]\n","Downloading data: 100%|██████████| 391k/391k [00:00<00:00, 1.41MB/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8c10e3e65fb4eca9045d51b3e8e8a4f","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4da8a450d3f443486f313067065703f","version_major":2,"version_minor":0},"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","\n","books = load_dataset(\"SesameLab/translation-dataset-for-NLLB-clean\")"]},{"cell_type":"markdown","metadata":{"id":"0v6CeAddTxjv"},"source":["We May split the dataset into a train and test set with the [train_test_split](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.train_test_split) if we need to but here the data was already split to train and val sets."]},{"cell_type":"markdown","metadata":{"id":"p8j9hQEhTxjw"},"source":["Then take a look at an example:"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T16:45:35.268796Z","iopub.status.busy":"2024-05-26T16:45:35.267940Z","iopub.status.idle":"2024-05-26T16:45:35.274622Z","shell.execute_reply":"2024-05-26T16:45:35.273964Z","shell.execute_reply.started":"2024-05-26T16:45:35.268752Z"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1715107883672,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"_82YexXEObTa","trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['Egyptian_Text', 'English_Text'],\n","        num_rows: 12496\n","    })\n","    validation: Dataset({\n","        features: ['Egyptian_Text', 'English_Text'],\n","        num_rows: 2286\n","    })\n","})"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["books"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T16:45:41.550133Z","iopub.status.busy":"2024-05-26T16:45:41.549500Z","iopub.status.idle":"2024-05-26T16:45:41.558830Z","shell.execute_reply":"2024-05-26T16:45:41.558243Z","shell.execute_reply.started":"2024-05-26T16:45:41.550101Z"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1715107883672,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"grV7i7-KOjTJ","outputId":"3b6d376c-dc6e-4e62-9bfe-8e6df2828123","trusted":true},"outputs":[{"data":{"text/plain":["{'Egyptian_Text': 'ليه لما بنكلم الحيوانات بنكلمهم بالانجليزى هما مش بيفهموا عربى .',\n"," 'English_Text': 'Why, when we talk to animals, we speak to them in English, but they do not understand Arabic.'}"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["books[\"validation\"][0]"]},{"cell_type":"markdown","metadata":{"id":"8oh3i6DjTxjw"},"source":["## Preprocess"]},{"cell_type":"markdown","metadata":{"id":"CtIvwSYSTxjx"},"source":["The next step is to rename the columns for the datasetdict\n","and to load a NLLB tokenizer to process the Egyptian-English language pairs:"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T16:45:45.948366Z","iopub.status.busy":"2024-05-26T16:45:45.947753Z","iopub.status.idle":"2024-05-26T16:45:45.960283Z","shell.execute_reply":"2024-05-26T16:45:45.959522Z","shell.execute_reply.started":"2024-05-26T16:45:45.948335Z"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715107883672,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"kQh6HMsqsF8A","outputId":"2bae159f-d76d-4b5d-da4f-59bfbfcfe36c","trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'text_target'],\n","        num_rows: 12496\n","    })\n","    validation: Dataset({\n","        features: ['text', 'text_target'],\n","        num_rows: 2286\n","    })\n","})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["books=books.rename_column(\"Egyptian_Text\", \"text\")\n","books=books.rename_column(\"English_Text\", \"text_target\")\n","books"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:42:53.840234Z","iopub.status.busy":"2024-05-26T18:42:53.839871Z","iopub.status.idle":"2024-05-26T18:42:55.033105Z","shell.execute_reply":"2024-05-26T18:42:55.032302Z","shell.execute_reply.started":"2024-05-26T18:42:53.840206Z"},"executionInfo":{"elapsed":6616,"status":"ok","timestamp":1715107890284,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"byW15dBeTxjx","outputId":"13081071-24a2-4e71-d075-d90eb2dbb3ea","trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","checkpoint = \"facebook/nllb-200-distilled-600M\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint, src_lang=\"ar\",tgt_lang=\"en\", max_length=256)"]},{"cell_type":"markdown","metadata":{"id":"meQLPs48Txjx"},"source":["The preprocessing function you want to create needs to:\n","\n","\n","* Tokenize the input (English) and target (French) separately because you can't tokenize French text with a tokenizer pretrained on an English vocabulary.\n","* Truncate sequences to be no longer than the maximum length set by the `max_length` parameter."]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:43:53.475572Z","iopub.status.busy":"2024-05-26T18:43:53.475213Z","iopub.status.idle":"2024-05-26T18:43:53.486974Z","shell.execute_reply":"2024-05-26T18:43:53.486231Z","shell.execute_reply.started":"2024-05-26T18:43:53.475544Z"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715107890285,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"lCq9vpG1mN4N","outputId":"01297716-8961-405c-8019-ee4e9d12dccf","trusted":true},"outputs":[{"data":{"text/plain":["['en', '▁I', '▁am', '▁Dr', '.', '▁Ibrahim', '.', '</s>']"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["sample = books[\"train\"][12]\n","inputs = tokenizer(sample[\"text\"])\n","with tokenizer.as_target_tokenizer():\n","  outputs = tokenizer(sample[\"text_target\"])\n","print(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"]))\n","print(tokenizer.convert_ids_to_tokens(outputs[\"input_ids\"]))\n","tokenizer.convert_ids_to_tokens(outputs[\"input_ids\"])"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:43:58.613194Z","iopub.status.busy":"2024-05-26T18:43:58.612500Z","iopub.status.idle":"2024-05-26T18:43:58.619046Z","shell.execute_reply":"2024-05-26T18:43:58.618101Z","shell.execute_reply.started":"2024-05-26T18:43:58.613165Z"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715107890285,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"76El_EV4Txjx","trusted":true},"outputs":[],"source":["# prefix = \"translate Egyptian Arabic to English: \"\n","max_length = 256\n","\n","def preprocess_function(examples):\n","    inputs = examples[\"text\"]\n","    targets = examples[\"text_target\"]\n","    model_inputs = tokenizer(inputs, text_target=targets, max_length=max_length, truncation=True)\n","    return model_inputs"]},{"cell_type":"markdown","metadata":{"id":"rP3DCWhkTxjx"},"source":["To apply the preprocessing function over the entire dataset, use 🤗 Datasets [map](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map) method. You can speed up the `map` function by setting `batched=True` to process multiple elements of the dataset at once:"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:44:03.588098Z","iopub.status.busy":"2024-05-26T18:44:03.587298Z","iopub.status.idle":"2024-05-26T18:44:06.071047Z","shell.execute_reply":"2024-05-26T18:44:06.069842Z","shell.execute_reply.started":"2024-05-26T18:44:03.588066Z"},"executionInfo":{"elapsed":8848,"status":"ok","timestamp":1715107899131,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"GqFMclNZSAdB","outputId":"1acb9f9a-18e1-4c22-84c0-a5ba6acfb549","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ffdb45c1f22f4b518b95e501a57120c7","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/12496 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0dfc6129651944c485d3f3d56729d433","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2286 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_books = books.map(preprocess_function, batched=True)"]},{"cell_type":"markdown","metadata":{"id":"oIzJSa_pTxjx"},"source":["Now create a batch of examples using [DataCollatorForSeq2Seq](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DataCollatorForSeq2Seq). It's more efficient to *dynamically pad* the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length."]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:44:08.114499Z","iopub.status.busy":"2024-05-26T18:44:08.114140Z","iopub.status.idle":"2024-05-26T18:44:08.120674Z","shell.execute_reply":"2024-05-26T18:44:08.119983Z","shell.execute_reply.started":"2024-05-26T18:44:08.114473Z"},"executionInfo":{"elapsed":7112,"status":"ok","timestamp":1715107906232,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"wWfYlUCgTxjy","trusted":true},"outputs":[],"source":["from transformers import DataCollatorForSeq2Seq\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"]},{"cell_type":"markdown","metadata":{"id":"ngtHX_O8Txjy"},"source":["## Evaluate"]},{"cell_type":"markdown","metadata":{"id":"JfRc7QibTxjy"},"source":["Including a metric during training is often helpful for evaluating your model's performance. You can quickly load a evaluation method with the 🤗 [Evaluate](https://huggingface.co/docs/evaluate/index) library. For this task, load the [SacreBLEU](https://huggingface.co/spaces/evaluate-metric/sacrebleu) metric (see the 🤗 Evaluate [quick tour](https://huggingface.co/docs/evaluate/a_quick_tour) to learn more about how to load and compute a metric):"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:44:12.693984Z","iopub.status.busy":"2024-05-26T18:44:12.693619Z","iopub.status.idle":"2024-05-26T18:44:13.297419Z","shell.execute_reply":"2024-05-26T18:44:13.296583Z","shell.execute_reply.started":"2024-05-26T18:44:12.693955Z"},"executionInfo":{"elapsed":7017,"status":"ok","timestamp":1715107913247,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"KaKWKfnxTxjy","trusted":true},"outputs":[],"source":["import evaluate\n","\n","metric = evaluate.load(\"sacrebleu\")"]},{"cell_type":"markdown","metadata":{"id":"lLnty1QtTxjy"},"source":["Then create a function that passes your predictions and labels to [compute](https://huggingface.co/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute) to calculate the SacreBLEU score:"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:44:15.980314Z","iopub.status.busy":"2024-05-26T18:44:15.979545Z","iopub.status.idle":"2024-05-26T18:44:15.989895Z","shell.execute_reply":"2024-05-26T18:44:15.989128Z","shell.execute_reply.started":"2024-05-26T18:44:15.980282Z"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1715107913248,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"cCog_drJTxjy","trusted":true},"outputs":[],"source":["import numpy as np\n","\n","\n","def postprocess_text(preds, labels):\n","    preds = [pred.strip() for pred in preds]\n","    labels = [[label.strip()] for label in labels]\n","\n","    return preds, labels\n","\n","\n","def compute_metrics(eval_preds):\n","    preds, labels = eval_preds\n","    if isinstance(preds, tuple):\n","        preds = preds[0]\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n","    result = {\"bleu\": result[\"score\"]}\n","\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    result = {k: round(v, 4) for k, v in result.items()}\n","    return result"]},{"cell_type":"markdown","metadata":{"id":"1qHqG17WTxjy"},"source":["Your `compute_metrics` function is ready to go now, and you'll return to it when you setup your training."]},{"cell_type":"markdown","metadata":{"id":"p9-tD79LTxjy"},"source":["## Train"]},{"cell_type":"markdown","metadata":{"id":"4o3XZBb5Txjy"},"source":["<Tip>\n","\n","If you aren't familiar with finetuning a model with the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer), take a look at the basic tutorial [here](https://huggingface.co/docs/transformers/main/en/tasks/../training#train-with-pytorch-trainer)!\n","\n","</Tip>\n","\n","You're ready to start training your model now! Load T5 with [AutoModelForSeq2SeqLM](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForSeq2SeqLM):"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:44:23.823982Z","iopub.status.busy":"2024-05-26T18:44:23.823161Z","iopub.status.idle":"2024-05-26T18:44:26.618865Z","shell.execute_reply":"2024-05-26T18:44:26.618092Z","shell.execute_reply.started":"2024-05-26T18:44:23.823948Z"},"executionInfo":{"elapsed":6903,"status":"ok","timestamp":1715107920141,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"SBB6OodnTxjy","outputId":"1b783e76-301e-4e3a-dac2-dd46e56ec70f","trusted":true},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"]},{"cell_type":"markdown","metadata":{"id":"SkH1VuwcTxjz"},"source":["At this point, only three steps remain:\n","\n","1. Define your training hyperparameters in [Seq2SeqTrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Seq2SeqTrainingArguments). The only required parameter is `output_dir` which specifies where to save your model. You'll push this model to the Hub by setting `push_to_hub=True` (you need to be signed in to Hugging Face to upload your model). At the end of each epoch, the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) will evaluate the SacreBLEU metric and save the training checkpoint.\n","2. Pass the training arguments to [Seq2SeqTrainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Seq2SeqTrainer) along with the model, dataset, tokenizer, data collator, and `compute_metrics` function.\n","3. Call [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train) to finetune your model."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12938,"status":"ok","timestamp":1715107933077,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"M4Y9ziDfUCvc","outputId":"3765b0e2-0823-4c12-bf04-2fdb0d809890","trusted":true},"outputs":[],"source":["# uncomment, install and refresh your runtime if your on google colab\n","# !pip install transformers[torch] accelerate -U"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:45:49.554825Z","iopub.status.busy":"2024-05-26T18:45:49.554433Z","iopub.status.idle":"2024-05-26T18:45:49.719202Z","shell.execute_reply":"2024-05-26T18:45:49.718284Z","shell.execute_reply.started":"2024-05-26T18:45:49.554781Z"},"id":"0DiA_4wfTxjz","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]}],"source":["training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"NLLB_Egyptian_to_English256\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=3e-4,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    weight_decay=0.01,\n","    predict_with_generate=True,\n","    push_to_hub=True,\n","    num_train_epochs=3,\n","    logging_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    save_only_model=True\n",")\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_books[\"train\"],\n","    eval_dataset=tokenized_books[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:45:54.656913Z","iopub.status.busy":"2024-05-26T18:45:54.656532Z","iopub.status.idle":"2024-05-26T23:42:18.189413Z","shell.execute_reply":"2024-05-26T23:42:18.188580Z","shell.execute_reply.started":"2024-05-26T18:45:54.656884Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='18744' max='18744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [18744/18744 4:55:19, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.523700</td>\n","      <td>2.285564</td>\n","      <td>16.233100</td>\n","      <td>20.317600</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.788500</td>\n","      <td>2.226611</td>\n","      <td>17.554000</td>\n","      <td>20.360900</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.350800</td>\n","      <td>2.408262</td>\n","      <td>18.888600</td>\n","      <td>20.241500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 200}\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 200}\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 200}\n"]},{"data":{"text/plain":["TrainOutput(global_step=18744, training_loss=0.8876469897450517, metrics={'train_runtime': 17719.7513, 'train_samples_per_second': 2.116, 'train_steps_per_second': 1.058, 'total_flos': 2501566722539520.0, 'train_loss': 0.8876469897450517, 'epoch': 3.0})"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T23:42:18.191561Z","iopub.status.busy":"2024-05-26T23:42:18.191273Z","iopub.status.idle":"2024-05-26T23:42:33.302517Z","shell.execute_reply":"2024-05-26T23:42:33.301720Z","shell.execute_reply.started":"2024-05-26T23:42:18.191536Z"},"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1715107933077,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"preb4tYNTxjz","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 200}\n"]},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/mohamedsaeed823/NLLB_Egyptian_to_English256/commit/29f36d114a8a9581cb68016a6eca4c760a8021a5', commit_message='End of training', commit_description='', oid='29f36d114a8a9581cb68016a6eca4c760a8021a5', pr_url=None, pr_revision=None, pr_num=None)"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["trainer.push_to_hub()"]},{"cell_type":"markdown","metadata":{"id":"a7T2kBfWTxjz"},"source":["<Tip>\n","\n","For a more in-depth example of how to finetune a model for translation, take a look at the corresponding\n","[PyTorch notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation.ipynb)\n","or [TensorFlow notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation-tf.ipynb).\n","\n","</Tip>"]},{"cell_type":"markdown","metadata":{"id":"HZQwVs54Txjz"},"source":["## Inference"]},{"cell_type":"markdown","metadata":{"id":"YDC0y5edTxjz"},"source":["Great, now that you've finetuned a model, you can use it for inference!\n","\n","Come up with some text you'd like to translate to another language. For T5, you need to prefix your input depending on the task you're working on. For translation from English to French, you should prefix your input as shown below:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-10T17:09:46.445459Z","iopub.status.idle":"2024-05-10T17:09:46.445944Z","shell.execute_reply":"2024-05-10T17:09:46.445713Z","shell.execute_reply.started":"2024-05-10T17:09:46.445693Z"},"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1715107933077,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"9gdGo3K5Txjz","trusted":true},"outputs":[],"source":["text = \"ترجم من مصري لانجليزي باستخدام مودل NLLB\""]},{"cell_type":"markdown","metadata":{"id":"DdOO14BMTxj4"},"source":["The simplest way to try out your finetuned model for inference is to use it in a [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline). Instantiate a `pipeline` for translation with your model, and pass your text to it:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-10T17:09:46.447566Z","iopub.status.idle":"2024-05-10T17:09:46.448394Z","shell.execute_reply":"2024-05-10T17:09:46.448091Z","shell.execute_reply.started":"2024-05-10T17:09:46.448068Z"},"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1715107933077,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"owjxjPJ8Txj4","trusted":true},"outputs":[],"source":["from transformers import pipeline\n","\n","translator = pipeline(\"translation\", model=\"mohamedsaeed823/NLLB_Egyptian_Arabic_to_English\")\n","translator(text)"]},{"cell_type":"markdown","metadata":{"id":"3qWrCvXWTxj4"},"source":["You can also manually replicate the results of the `pipeline` if you'd like:\n","\n","Tokenize the text and return the `input_ids` as PyTorch tensors:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-10T17:09:46.449765Z","iopub.status.idle":"2024-05-10T17:09:46.450130Z","shell.execute_reply":"2024-05-10T17:09:46.449963Z","shell.execute_reply.started":"2024-05-10T17:09:46.449948Z"},"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1715107933077,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"VZcVZaI2Txj4","trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"mohamedsaeed823/NLLB_Egyptian_Arabic_to_English\")\n","inputs = tokenizer(text, return_tensors=\"pt\").input_ids"]},{"cell_type":"markdown","metadata":{"id":"3pwHUbitTxj4"},"source":["Use the [generate()](https://huggingface.co/docs/transformers/main/en/main_classes/text_generation#transformers.GenerationMixin.generate) method to create the translation. For more details about the different text generation strategies and parameters for controlling generation, check out the [Text Generation](https://huggingface.co/docs/transformers/main/en/tasks/../main_classes/text_generation) API."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-10T17:09:46.451291Z","iopub.status.idle":"2024-05-10T17:09:46.451638Z","shell.execute_reply":"2024-05-10T17:09:46.451477Z","shell.execute_reply.started":"2024-05-10T17:09:46.451464Z"},"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1715107933078,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"zGmvpycLTxj4","trusted":true},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"mohamedsaeed823/NLLB_Egyptian_Arabic_to_English\")\n","outputs = model.generate(inputs, max_new_tokens=40, do_sample=True, top_k=30, top_p=0.95)"]},{"cell_type":"markdown","metadata":{"id":"pO6xHuYLTxj4"},"source":["Decode the generated token ids back into text:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-10T17:09:46.452978Z","iopub.status.idle":"2024-05-10T17:09:46.453366Z","shell.execute_reply":"2024-05-10T17:09:46.453171Z","shell.execute_reply.started":"2024-05-10T17:09:46.453155Z"},"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1715107933078,"user":{"displayName":"runway musicblog","userId":"13562175345868373898"},"user_tz":-180},"id":"2Jjd4Z9HTxj4","trusted":true},"outputs":[],"source":["tokenizer.decode(outputs[0], skip_special_tokens=True)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/translation.ipynb","timestamp":1715090933404}]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"09404704cdbc4220bcd79d0fb3e88e8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_427658cccd2b450aa354cd0722ffe7e8","placeholder":"​","style":"IPY_MODEL_10981c09bc444ea49780738c99da7f16","value":"Map: 100%"}},"10981c09bc444ea49780738c99da7f16":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3427c74d5b654e9088a4b1029d538e98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"427658cccd2b450aa354cd0722ffe7e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"462d0d4795d1449394195f6da461ab06":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4852c56d3d9240a29bfcb4f4380affb1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_09404704cdbc4220bcd79d0fb3e88e8f","IPY_MODEL_a1a4d70deed646d5b63c55408e1c37cc","IPY_MODEL_b09cd6bc562f485c9e120985a22cb9a2"],"layout":"IPY_MODEL_5f9876e8160c40c19d8dffc91e2ac140"}},"50a3d4151c0f49d79f594396588cd823":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55868838540f4468a2fd9ca8d66b1d64":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57d1f642deda45cca65c1e4ef4e9bd07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_708ce78282e34d9abde073932cf3c021","placeholder":"​","style":"IPY_MODEL_3427c74d5b654e9088a4b1029d538e98","value":"Map: 100%"}},"5f9876e8160c40c19d8dffc91e2ac140":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"708ce78282e34d9abde073932cf3c021":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"786954747c2a4a66825680e5102ec2bd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bc7634cfd48438086afb76b56269c4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"908c9c643a7d42778f0a5ab597edfd6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_786954747c2a4a66825680e5102ec2bd","max":2500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3970008b68a485b93c3f12b550bd923","value":2500}},"9c9d7efcacd243ed8f1eafb83666dc88":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1a4d70deed646d5b63c55408e1c37cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c9d7efcacd243ed8f1eafb83666dc88","max":9996,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e7845c1a52b1420abd59c76627f572ed","value":9996}},"addfd9dc6f22483ba350b4440775ce81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_57d1f642deda45cca65c1e4ef4e9bd07","IPY_MODEL_908c9c643a7d42778f0a5ab597edfd6f","IPY_MODEL_f122e0c6bac14bd784dbeff00a95dd09"],"layout":"IPY_MODEL_cdedb3abcbd3407fa988d069f7bf791b"}},"b09cd6bc562f485c9e120985a22cb9a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_462d0d4795d1449394195f6da461ab06","placeholder":"​","style":"IPY_MODEL_7bc7634cfd48438086afb76b56269c4b","value":" 9996/9996 [00:05&lt;00:00, 1596.14 examples/s]"}},"c3970008b68a485b93c3f12b550bd923":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cdedb3abcbd3407fa988d069f7bf791b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7845c1a52b1420abd59c76627f572ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f122e0c6bac14bd784dbeff00a95dd09":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55868838540f4468a2fd9ca8d66b1d64","placeholder":"​","style":"IPY_MODEL_50a3d4151c0f49d79f594396588cd823","value":" 2500/2500 [00:01&lt;00:00, 2088.59 examples/s]"}}}}},"nbformat":4,"nbformat_minor":4}
